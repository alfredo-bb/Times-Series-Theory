{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in c:\\users\\alfredo\\appdata\\roaming\\python\\python38\\site-packages (0.13.1)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\alfredo\\anaconda3\\lib\\site-packages (from statsmodels) (0.5.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\alfredo\\anaconda3\\lib\\site-packages (from statsmodels) (1.19.5)\n",
      "Requirement already satisfied: scipy>=1.3 in c:\\users\\alfredo\\anaconda3\\lib\\site-packages (from statsmodels) (1.5.2)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\alfredo\\anaconda3\\lib\\site-packages (from statsmodels) (1.3.4)\n",
      "Requirement already satisfied: six in c:\\users\\alfredo\\appdata\\roaming\\python\\python38\\site-packages (from patsy>=0.5.2->statsmodels) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\alfredo\\anaconda3\\lib\\site-packages (from pandas>=0.25->statsmodels) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\alfredo\\appdata\\roaming\\python\\python38\\site-packages (from pandas>=0.25->statsmodels) (2.8.1)\n",
      "Collecting wooldridge\n",
      "  Downloading wooldridge-0.4.4-py3-none-any.whl (5.1 MB)\n",
      "Requirement already satisfied: pandas in c:\\users\\alfredo\\anaconda3\\lib\\site-packages (from wooldridge) (1.3.4)\n",
      "Requirement already satisfied: numpy>=1.17.3; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\" in c:\\users\\alfredo\\anaconda3\\lib\\site-packages (from pandas->wooldridge) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\alfredo\\appdata\\roaming\\python\\python38\\site-packages (from pandas->wooldridge) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\alfredo\\anaconda3\\lib\\site-packages (from pandas->wooldridge) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alfredo\\appdata\\roaming\\python\\python38\\site-packages (from python-dateutil>=2.7.3->pandas->wooldridge) (1.15.0)\n",
      "Installing collected packages: wooldridge\n",
      "Successfully installed wooldridge-0.4.4\n"
     ]
    }
   ],
   "source": [
    "!pip install statsmodels\n",
    "!pip install wooldridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wooldridge as wo\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importamos datos de datawoo. el objetivo a calcular es wage\n",
    "df=wo.dataWoo(\"wage1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regresion simple es cuando sólo hayuna variable dependiente. Es el modelo mas sencillo de interpretar.\n",
    "#la relacion entre variables es una relacion lineal. y = b0 + b1*x (una recta)\n",
    "#empezamos mirando la relacion entre el salario y la educacion\n",
    "\n",
    "#el priemr paso es calcular b0 y b1. b es igual a (x'x elevado a la -1)*x'y \n",
    "# x son nuestros datos e \"y\" el resultado a calcular(salario en este caso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vamos a decir que x es la educacion, ya que creemos que es una variable importante.\n",
    "#lo pasamos a un vector poniendo el to_numpy\n",
    "\n",
    "x=df[\"educ\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 12, 11,  8, 12, 16, 18, 12, 12, 17, 16, 13, 12, 12, 12, 16, 12,\n",
       "       13, 12, 12, 12, 12, 16, 12, 11, 16, 16, 16, 15,  8, 14, 14, 13, 12,\n",
       "       12, 16, 12,  4, 14, 12, 12, 12, 14, 11, 13, 15, 10, 12, 14, 12, 12,\n",
       "       16, 12, 12, 12, 15, 16,  8, 18, 16, 13, 14, 10, 10, 14, 14, 16, 12,\n",
       "       16, 12, 16, 17, 12, 12, 12, 13, 12, 12, 12, 18,  9, 16, 10, 12, 12,\n",
       "       12, 12, 12,  8, 12, 12, 14, 12, 12, 12,  9, 13, 12, 14, 12, 15, 12,\n",
       "       12, 12, 14, 15, 12, 12, 12, 17, 11, 18, 12, 14, 14, 10, 14, 12, 15,\n",
       "        8, 16, 14, 15, 12, 18, 16, 10,  8, 10, 11, 18, 15, 12, 11, 12, 12,\n",
       "       14, 16,  2, 14, 16, 12, 12, 13, 12, 15, 10, 12, 16, 13,  9, 12, 13,\n",
       "       12, 12, 14, 16, 16,  9, 18, 10, 10, 13, 12, 18, 13, 12, 13, 13, 13,\n",
       "       18, 12, 12, 13, 12, 12, 12, 14, 10, 12, 16, 16, 12, 14, 12, 12, 12,\n",
       "       12, 12, 12, 12, 16, 16, 14, 11, 16, 12, 12, 17, 12, 12, 16,  8, 12,\n",
       "       12, 12, 16, 12, 12,  9, 13, 16, 14,  8, 14, 13, 12, 18,  9,  8,  8,\n",
       "       12, 14, 12, 16,  8, 13,  9, 16, 12, 15, 11, 14, 12, 12, 12, 18, 12,\n",
       "       12, 12, 12, 12, 12, 14, 16, 12, 14, 11, 12, 10, 12,  6, 13, 12, 10,\n",
       "       12, 14, 13, 12, 18, 12, 12, 12, 12, 12,  8, 13, 13, 14, 12, 10, 16,\n",
       "       12, 16, 12, 14, 18, 17, 13, 14, 15, 14, 12,  8, 12, 12,  8, 12,  9,\n",
       "       12, 16, 12, 16, 12, 12, 13, 10,  6, 12, 12, 16, 12,  8, 12,  6,  4,\n",
       "       11, 11,  7, 12, 18, 12, 16, 12, 14, 12, 10, 10,  9, 10, 12, 12, 12,\n",
       "       10, 16, 16, 16, 12, 12,  7,  8, 16, 16, 18, 13, 10, 16, 14, 16, 12,\n",
       "        9, 11, 11, 12, 11, 12, 12, 12, 12, 14, 14, 18, 12, 12, 12, 11, 12,\n",
       "       17, 16, 13, 13, 12, 14, 14, 11, 10,  8, 14, 12, 10, 17,  9, 12, 12,\n",
       "       14, 16, 12, 10,  0, 14, 15, 16, 12, 11, 11, 12, 13, 12, 13, 16, 15,\n",
       "       16, 15, 12, 18,  6,  6, 12, 12, 16,  9, 12, 11, 10, 12,  8,  9, 17,\n",
       "       16, 11, 10,  8, 13, 14, 13, 11,  7, 16, 12, 13, 14, 16, 14, 11,  8,\n",
       "       14, 17, 10, 12, 12, 18, 14, 18, 12, 16, 14, 12,  9, 12, 12, 17, 12,\n",
       "       15, 17, 16, 12, 15, 16, 12, 15, 12, 12, 12, 12, 16, 11, 14, 14, 13,\n",
       "       14, 12, 12,  8, 12,  3, 11, 15, 11, 12,  4,  9, 12, 12, 11, 12, 16,\n",
       "       13, 15, 16, 12, 12, 12,  9, 10, 12, 11,  8,  6, 16, 12, 12, 16, 12,\n",
       "       10, 13, 13, 14, 16, 10, 12, 12, 11,  0,  5, 16, 16,  9, 15, 12, 12,\n",
       "       12, 13, 12,  7, 17, 12, 12, 14, 12, 13, 12, 16, 10, 15, 16, 14],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hacemos un vector de solo 1, y la concatenamos a cada valor de  1 \n",
    "#ponemos el vector de 1 a cada valor. este vector es b0\n",
    "X=np.c_[np.ones(len(x)),x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lwage es el logaritmo del salario. se hace con el logaritmo para acercarnos al supusto de que los errores sean normales\n",
    "y=df[\"lwage\"].to_numpy()\n",
    "y=y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58377267],\n",
       "       [0.08274437]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hacemos la inversa de la multiplicacion de X traspuesta por X. se pone @ para que se haga multiplicacion de matrices\n",
    "#despues lo multiplicamos por la multiplicacion de X por la traspuesta de Y.\n",
    "# el resultado es el punto de origen (intercepto) y la pendiente\n",
    "#y = b0 + b1*x (una recta) ----> #y = 0.58377267 + 0.08274437*x \n",
    "\n",
    "\n",
    "recta=np.linalg.inv(X.T@X)@(X.T@y)\n",
    "recta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1433095e640>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x,y)\n",
    "plt.plot(x,recta[0]+recta[1]*x,color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hacemos lo mismo pero con la Api de statmodels\n",
    "#lwage es la variable dependiente y educ es la variable independiente, esto lo decimos poniendole la ~\n",
    "reg=smf.ols(formula=\"lwage~educ\",data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado=reg.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    0.583773\n",
       "educ         0.082744\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>lwage</td>      <th>  R-squared:         </th> <td>   0.186</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.184</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   119.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 27 Jan 2022</td> <th>  Prob (F-statistic):</th> <td>3.27e-25</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:01:39</td>     <th>  Log-Likelihood:    </th> <td> -359.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   526</td>      <th>  AIC:               </th> <td>   722.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   524</td>      <th>  BIC:               </th> <td>   731.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.5838</td> <td>    0.097</td> <td>    5.998</td> <td> 0.000</td> <td>    0.393</td> <td>    0.775</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educ</th>      <td>    0.0827</td> <td>    0.008</td> <td>   10.935</td> <td> 0.000</td> <td>    0.068</td> <td>    0.098</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>11.804</td> <th>  Durbin-Watson:     </th> <td>   1.801</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.003</td> <th>  Jarque-Bera (JB):  </th> <td>  13.811</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.268</td> <th>  Prob(JB):          </th> <td> 0.00100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.586</td> <th>  Cond. No.          </th> <td>    60.2</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  lwage   R-squared:                       0.186\n",
       "Model:                            OLS   Adj. R-squared:                  0.184\n",
       "Method:                 Least Squares   F-statistic:                     119.6\n",
       "Date:                Thu, 27 Jan 2022   Prob (F-statistic):           3.27e-25\n",
       "Time:                        16:01:39   Log-Likelihood:                -359.38\n",
       "No. Observations:                 526   AIC:                             722.8\n",
       "Df Residuals:                     524   BIC:                             731.3\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.5838      0.097      5.998      0.000       0.393       0.775\n",
       "educ           0.0827      0.008     10.935      0.000       0.068       0.098\n",
       "==============================================================================\n",
       "Omnibus:                       11.804   Durbin-Watson:                   1.801\n",
       "Prob(Omnibus):                  0.003   Jarque-Bera (JB):               13.811\n",
       "Skew:                           0.268   Prob(JB):                      0.00100\n",
       "Kurtosis:                       3.586   Cond. No.                         60.2\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado.summary()\n",
    "\n",
    "#R-squared es el porcentaje de varianza explicado por nuestra variable independiente (educacion). \n",
    "# la educacion indica un 18.6% del cambio en el salario\n",
    "#si el Prob (F-statistic)es muy pequeño significa que el modelo funciona bien, es significativo. que tiene causalidad y tiene r\n",
    "# relacion real entre ls variables.\n",
    "# si es un valor por encima de 0.05 el modelo no es significativo.\n",
    "\n",
    "#ej: el precio del arroz en china y el numero de semaforos en la calle en argentina pueden tener una relacion, \n",
    "#pero no tienen ninguna causalidad.\n",
    "\n",
    "#-----\n",
    "#el intervalo de Intercept es 0.393\t0.775. si este valor pasa por 0,el modelo no es significativo \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para saber la variacion del salario, multiplicamos por 100 el coeficiente de la variable independiente (educacion)\n",
    "#por cada añlo de educacion añadido seria y = 0.58377267 + 8.274437*x, siendo x el numero de años añadidos\n",
    "\n",
    "y = 0.58377267 + 0.08274437*x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regresion lineal multiple : con más de una variable independiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg=smf.ols(formula=\"lwage~educ+exper\",data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>lwage</td>      <th>  R-squared:         </th> <td>   0.249</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.246</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   86.86</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 27 Jan 2022</td> <th>  Prob (F-statistic):</th> <td>2.68e-33</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:22:07</td>     <th>  Log-Likelihood:    </th> <td> -338.01</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   526</td>      <th>  AIC:               </th> <td>   682.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   523</td>      <th>  BIC:               </th> <td>   694.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.2169</td> <td>    0.109</td> <td>    1.997</td> <td> 0.046</td> <td>    0.004</td> <td>    0.430</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educ</th>      <td>    0.0979</td> <td>    0.008</td> <td>   12.848</td> <td> 0.000</td> <td>    0.083</td> <td>    0.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exper</th>     <td>    0.0103</td> <td>    0.002</td> <td>    6.653</td> <td> 0.000</td> <td>    0.007</td> <td>    0.013</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 7.740</td> <th>  Durbin-Watson:     </th> <td>   1.789</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.021</td> <th>  Jarque-Bera (JB):  </th> <td>   9.485</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.165</td> <th>  Prob(JB):          </th> <td> 0.00872</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.569</td> <th>  Cond. No.          </th> <td>    130.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  lwage   R-squared:                       0.249\n",
       "Model:                            OLS   Adj. R-squared:                  0.246\n",
       "Method:                 Least Squares   F-statistic:                     86.86\n",
       "Date:                Thu, 27 Jan 2022   Prob (F-statistic):           2.68e-33\n",
       "Time:                        16:22:07   Log-Likelihood:                -338.01\n",
       "No. Observations:                 526   AIC:                             682.0\n",
       "Df Residuals:                     523   BIC:                             694.8\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.2169      0.109      1.997      0.046       0.004       0.430\n",
       "educ           0.0979      0.008     12.848      0.000       0.083       0.113\n",
       "exper          0.0103      0.002      6.653      0.000       0.007       0.013\n",
       "==============================================================================\n",
       "Omnibus:                        7.740   Durbin-Watson:                   1.789\n",
       "Prob(Omnibus):                  0.021   Jarque-Bera (JB):                9.485\n",
       "Skew:                           0.165   Prob(JB):                      0.00872\n",
       "Kurtosis:                       3.569   Cond. No.                         130.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado=reg.fit()\n",
    "resultado.summary()\n",
    "\n",
    "#educacion y experiencia indican en un 25% la variacion del salario\n",
    "#siempre que añadamos varibales el R-squared va a subir asi que tomamos el Adj. R-squared\n",
    "\n",
    "#el Prob (F-statistic) es èqueño, el modelo es significativo. alguna de las variables es estadistocamente significativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2422198739390637"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#como antes hemos hecho el logaritmo del salario, hacemos el exponencial. si no tuvieramos nada de educacion\n",
    "#ni experiencia, el salario seria igual a 1.24 por hora.\n",
    "#si incremento mi educacion en un año, mi salario va a ser un 9.79% mayor (coef -educ)\n",
    "#si incremento mi experiencia en un año, mi salario va a ser un 1.03% mayor (coef -exper)\n",
    "\n",
    "#el intercepto del modelo tiene un P valor de 0.046. a partir de 0.05 deja de ser significativo, \n",
    "#por lo que esta en el limite.\n",
    "#ninguno de los P interceptos pasa por 0 , asi que todos son significativos.\n",
    "\n",
    "np.exp (0.2169)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x14330a73190>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df[\"exper\"],df[\"wage\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg=smf.ols(formula=\"lwage~educ+exper+expersq\",data=df)\n",
    "\n",
    "#añadimos el cuadrado de la experiencia, porque a partir de ciuerta edad la experiencia no cuneta tanto e incluso\n",
    "#puede llegar a ser un handicap (p.ej personas mayores de 60 años)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>lwage</td>      <th>  R-squared:         </th> <td>   0.300</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.296</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   74.67</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 27 Jan 2022</td> <th>  Prob (F-statistic):</th> <td>3.38e-40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:35:35</td>     <th>  Log-Likelihood:    </th> <td> -319.53</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   526</td>      <th>  AIC:               </th> <td>   647.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   522</td>      <th>  BIC:               </th> <td>   664.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.1280</td> <td>    0.106</td> <td>    1.208</td> <td> 0.227</td> <td>   -0.080</td> <td>    0.336</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educ</th>      <td>    0.0904</td> <td>    0.007</td> <td>   12.100</td> <td> 0.000</td> <td>    0.076</td> <td>    0.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exper</th>     <td>    0.0410</td> <td>    0.005</td> <td>    7.892</td> <td> 0.000</td> <td>    0.031</td> <td>    0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>expersq</th>   <td>   -0.0007</td> <td>    0.000</td> <td>   -6.164</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 5.379</td> <th>  Durbin-Watson:     </th> <td>   1.785</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.068</td> <th>  Jarque-Bera (JB):  </th> <td>   7.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.028</td> <th>  Prob(JB):          </th> <td>  0.0280</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.568</td> <th>  Cond. No.          </th> <td>4.24e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 4.24e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  lwage   R-squared:                       0.300\n",
       "Model:                            OLS   Adj. R-squared:                  0.296\n",
       "Method:                 Least Squares   F-statistic:                     74.67\n",
       "Date:                Thu, 27 Jan 2022   Prob (F-statistic):           3.38e-40\n",
       "Time:                        16:35:35   Log-Likelihood:                -319.53\n",
       "No. Observations:                 526   AIC:                             647.1\n",
       "Df Residuals:                     522   BIC:                             664.1\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.1280      0.106      1.208      0.227      -0.080       0.336\n",
       "educ           0.0904      0.007     12.100      0.000       0.076       0.105\n",
       "exper          0.0410      0.005      7.892      0.000       0.031       0.051\n",
       "expersq       -0.0007      0.000     -6.164      0.000      -0.001      -0.000\n",
       "==============================================================================\n",
       "Omnibus:                        5.379   Durbin-Watson:                   1.785\n",
       "Prob(Omnibus):                  0.068   Jarque-Bera (JB):                7.152\n",
       "Skew:                           0.028   Prob(JB):                       0.0280\n",
       "Kurtosis:                       3.568   Cond. No.                     4.24e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 4.24e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado=reg.fit()\n",
    "resultado.summary()\n",
    "\n",
    "#el Adj. R-squared dice quelas variables explicanun 30% del cambio\n",
    "#Prob (F-statistic):\t3.38e-40 es muy pequeño, nos dice que el modelo es significativo\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.28571428571429"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0410/(-2*-0.0007)\n",
    "\n",
    "#a los 29 años de experiencia es cuando alcanzas tu máximo salario posible,\n",
    "#teniendo en cuenta solamente la experiencia y la educacion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14330c80070>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df[\"exper\"],df[\"wage\"])\n",
    "plt.plot(df[\"exper\"],df[\"exper\"]*0.0410+df[\"expersq\"]*-0.0007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name of dataset: wage1\n",
      "no of variables: 24\n",
      "no of observations: 526\n",
      "\n",
      "+----------+---------------------------------+\n",
      "| variable | label                           |\n",
      "+----------+---------------------------------+\n",
      "| wage     | average hourly earnings         |\n",
      "| educ     | years of education              |\n",
      "| exper    | years potential experience      |\n",
      "| tenure   | years with current employer     |\n",
      "| nonwhite | =1 if nonwhite                  |\n",
      "| female   | =1 if female                    |\n",
      "| married  | =1 if married                   |\n",
      "| numdep   | number of dependents            |\n",
      "| smsa     | =1 if live in SMSA              |\n",
      "| northcen | =1 if live in north central U.S |\n",
      "| south    | =1 if live in southern region   |\n",
      "| west     | =1 if live in western region    |\n",
      "| construc | =1 if work in construc. indus.  |\n",
      "| ndurman  | =1 if in nondur. manuf. indus.  |\n",
      "| trcommpu | =1 if in trans, commun, pub ut  |\n",
      "| trade    | =1 if in wholesale or retail    |\n",
      "| services | =1 if in services indus.        |\n",
      "| profserv | =1 if in prof. serv. indus.     |\n",
      "| profocc  | =1 if in profess. occupation    |\n",
      "| clerocc  | =1 if in clerical occupation    |\n",
      "| servocc  | =1 if in service occupation     |\n",
      "| lwage    | log(wage)                       |\n",
      "| expersq  | exper^2                         |\n",
      "| tenursq  | tenure^2                        |\n",
      "+----------+---------------------------------+\n",
      "\n",
      "These are data from the 1976 Current Population Survey, collected by\n",
      "Henry Farber when he and I were colleagues at MIT in 1988.\n"
     ]
    }
   ],
   "source": [
    "wo.data(\"wage1\",description=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hago un nuevo modelo que incluya tenure, los años con el mismo empleador\n",
    "\n",
    "reg=smf.ols(formula=\"lwage~educ+exper+expersq+tenure\",data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>lwage</td>      <th>  R-squared:         </th> <td>   0.359</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.355</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   73.09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 27 Jan 2022</td> <th>  Prob (F-statistic):</th> <td>3.81e-49</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:51:50</td>     <th>  Log-Likelihood:    </th> <td> -296.29</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   526</td>      <th>  AIC:               </th> <td>   602.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   521</td>      <th>  BIC:               </th> <td>   623.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.1983</td> <td>    0.102</td> <td>    1.945</td> <td> 0.052</td> <td>   -0.002</td> <td>    0.399</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educ</th>      <td>    0.0853</td> <td>    0.007</td> <td>   11.873</td> <td> 0.000</td> <td>    0.071</td> <td>    0.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exper</th>     <td>    0.0329</td> <td>    0.005</td> <td>    6.425</td> <td> 0.000</td> <td>    0.023</td> <td>    0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>expersq</th>   <td>   -0.0007</td> <td>    0.000</td> <td>   -5.945</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>    <td>    0.0208</td> <td>    0.003</td> <td>    6.938</td> <td> 0.000</td> <td>    0.015</td> <td>    0.027</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.093</td> <th>  Durbin-Watson:     </th> <td>   1.776</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  26.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.114</td> <th>  Prob(JB):          </th> <td>2.20e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.066</td> <th>  Cond. No.          </th> <td>4.26e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 4.26e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  lwage   R-squared:                       0.359\n",
       "Model:                            OLS   Adj. R-squared:                  0.355\n",
       "Method:                 Least Squares   F-statistic:                     73.09\n",
       "Date:                Thu, 27 Jan 2022   Prob (F-statistic):           3.81e-49\n",
       "Time:                        16:51:50   Log-Likelihood:                -296.29\n",
       "No. Observations:                 526   AIC:                             602.6\n",
       "Df Residuals:                     521   BIC:                             623.9\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.1983      0.102      1.945      0.052      -0.002       0.399\n",
       "educ           0.0853      0.007     11.873      0.000       0.071       0.099\n",
       "exper          0.0329      0.005      6.425      0.000       0.023       0.043\n",
       "expersq       -0.0007      0.000     -5.945      0.000      -0.001      -0.000\n",
       "tenure         0.0208      0.003      6.938      0.000       0.015       0.027\n",
       "==============================================================================\n",
       "Omnibus:                       14.093   Durbin-Watson:                   1.776\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               26.057\n",
       "Skew:                          -0.114   Prob(JB):                     2.20e-06\n",
       "Kurtosis:                       4.066   Cond. No.                     4.26e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 4.26e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado=reg.fit()\n",
    "resultado.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage</th>\n",
       "      <th>educ</th>\n",
       "      <th>exper</th>\n",
       "      <th>tenure</th>\n",
       "      <th>nonwhite</th>\n",
       "      <th>female</th>\n",
       "      <th>married</th>\n",
       "      <th>numdep</th>\n",
       "      <th>smsa</th>\n",
       "      <th>northcen</th>\n",
       "      <th>south</th>\n",
       "      <th>west</th>\n",
       "      <th>construc</th>\n",
       "      <th>ndurman</th>\n",
       "      <th>trcommpu</th>\n",
       "      <th>trade</th>\n",
       "      <th>services</th>\n",
       "      <th>profserv</th>\n",
       "      <th>profocc</th>\n",
       "      <th>clerocc</th>\n",
       "      <th>servocc</th>\n",
       "      <th>lwage</th>\n",
       "      <th>expersq</th>\n",
       "      <th>tenursq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wage</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.405903</td>\n",
       "      <td>0.112903</td>\n",
       "      <td>0.346890</td>\n",
       "      <td>-0.038520</td>\n",
       "      <td>-0.340098</td>\n",
       "      <td>0.228817</td>\n",
       "      <td>-0.053760</td>\n",
       "      <td>0.177885</td>\n",
       "      <td>-0.029124</td>\n",
       "      <td>-0.102503</td>\n",
       "      <td>0.087732</td>\n",
       "      <td>0.004034</td>\n",
       "      <td>0.073725</td>\n",
       "      <td>0.055940</td>\n",
       "      <td>-0.189848</td>\n",
       "      <td>-0.141624</td>\n",
       "      <td>0.085204</td>\n",
       "      <td>0.441770</td>\n",
       "      <td>-0.140837</td>\n",
       "      <td>-0.253078</td>\n",
       "      <td>0.937062</td>\n",
       "      <td>0.030238</td>\n",
       "      <td>0.267419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educ</th>\n",
       "      <td>0.405903</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.299542</td>\n",
       "      <td>-0.056173</td>\n",
       "      <td>-0.084654</td>\n",
       "      <td>-0.085029</td>\n",
       "      <td>0.068881</td>\n",
       "      <td>-0.215291</td>\n",
       "      <td>0.224309</td>\n",
       "      <td>0.061372</td>\n",
       "      <td>-0.116625</td>\n",
       "      <td>0.016343</td>\n",
       "      <td>-0.077411</td>\n",
       "      <td>-0.012461</td>\n",
       "      <td>0.107736</td>\n",
       "      <td>-0.059204</td>\n",
       "      <td>-0.072659</td>\n",
       "      <td>0.214198</td>\n",
       "      <td>0.496768</td>\n",
       "      <td>-0.008324</td>\n",
       "      <td>-0.163345</td>\n",
       "      <td>0.431053</td>\n",
       "      <td>-0.331256</td>\n",
       "      <td>-0.069106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exper</th>\n",
       "      <td>0.112903</td>\n",
       "      <td>-0.299542</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.499291</td>\n",
       "      <td>0.014356</td>\n",
       "      <td>-0.041626</td>\n",
       "      <td>0.316984</td>\n",
       "      <td>-0.056319</td>\n",
       "      <td>-0.117260</td>\n",
       "      <td>0.010588</td>\n",
       "      <td>0.050323</td>\n",
       "      <td>-0.017398</td>\n",
       "      <td>-0.072841</td>\n",
       "      <td>0.101432</td>\n",
       "      <td>-0.048267</td>\n",
       "      <td>-0.104626</td>\n",
       "      <td>0.041499</td>\n",
       "      <td>-0.020599</td>\n",
       "      <td>-0.005615</td>\n",
       "      <td>-0.040385</td>\n",
       "      <td>-0.071080</td>\n",
       "      <td>0.111373</td>\n",
       "      <td>0.960971</td>\n",
       "      <td>0.422942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tenure</th>\n",
       "      <td>0.346890</td>\n",
       "      <td>-0.056173</td>\n",
       "      <td>0.499291</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011589</td>\n",
       "      <td>-0.197910</td>\n",
       "      <td>0.239889</td>\n",
       "      <td>-0.027037</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.014093</td>\n",
       "      <td>-0.025067</td>\n",
       "      <td>-0.021291</td>\n",
       "      <td>-0.025888</td>\n",
       "      <td>0.160519</td>\n",
       "      <td>0.063885</td>\n",
       "      <td>-0.126224</td>\n",
       "      <td>-0.062604</td>\n",
       "      <td>-0.059691</td>\n",
       "      <td>0.090624</td>\n",
       "      <td>-0.072831</td>\n",
       "      <td>-0.112679</td>\n",
       "      <td>0.325538</td>\n",
       "      <td>0.459223</td>\n",
       "      <td>0.921564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nonwhite</th>\n",
       "      <td>-0.038520</td>\n",
       "      <td>-0.084654</td>\n",
       "      <td>0.014356</td>\n",
       "      <td>0.011589</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.010917</td>\n",
       "      <td>-0.062259</td>\n",
       "      <td>0.077701</td>\n",
       "      <td>-0.014147</td>\n",
       "      <td>-0.080201</td>\n",
       "      <td>0.102098</td>\n",
       "      <td>-0.002287</td>\n",
       "      <td>0.046109</td>\n",
       "      <td>0.036261</td>\n",
       "      <td>-0.072328</td>\n",
       "      <td>-0.048486</td>\n",
       "      <td>0.094866</td>\n",
       "      <td>-0.056680</td>\n",
       "      <td>-0.088552</td>\n",
       "      <td>-0.034138</td>\n",
       "      <td>-0.028769</td>\n",
       "      <td>-0.038888</td>\n",
       "      <td>0.009348</td>\n",
       "      <td>-0.007203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>-0.340098</td>\n",
       "      <td>-0.085029</td>\n",
       "      <td>-0.041626</td>\n",
       "      <td>-0.197910</td>\n",
       "      <td>-0.010917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.166128</td>\n",
       "      <td>0.033148</td>\n",
       "      <td>0.016545</td>\n",
       "      <td>0.015453</td>\n",
       "      <td>-0.044438</td>\n",
       "      <td>0.054417</td>\n",
       "      <td>-0.082032</td>\n",
       "      <td>-0.092721</td>\n",
       "      <td>-0.018964</td>\n",
       "      <td>-0.053351</td>\n",
       "      <td>0.108833</td>\n",
       "      <td>0.215939</td>\n",
       "      <td>-0.177376</td>\n",
       "      <td>0.355233</td>\n",
       "      <td>0.159226</td>\n",
       "      <td>-0.373677</td>\n",
       "      <td>-0.027860</td>\n",
       "      <td>-0.175623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>married</th>\n",
       "      <td>0.228817</td>\n",
       "      <td>0.068881</td>\n",
       "      <td>0.316984</td>\n",
       "      <td>0.239889</td>\n",
       "      <td>-0.062259</td>\n",
       "      <td>-0.166128</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.154497</td>\n",
       "      <td>-0.097230</td>\n",
       "      <td>-0.011716</td>\n",
       "      <td>0.075150</td>\n",
       "      <td>-0.022277</td>\n",
       "      <td>0.007452</td>\n",
       "      <td>0.079615</td>\n",
       "      <td>0.038239</td>\n",
       "      <td>-0.136572</td>\n",
       "      <td>-0.054906</td>\n",
       "      <td>0.064603</td>\n",
       "      <td>0.085544</td>\n",
       "      <td>0.025711</td>\n",
       "      <td>-0.157040</td>\n",
       "      <td>0.270669</td>\n",
       "      <td>0.217289</td>\n",
       "      <td>0.166822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numdep</th>\n",
       "      <td>-0.053760</td>\n",
       "      <td>-0.215291</td>\n",
       "      <td>-0.056319</td>\n",
       "      <td>-0.027037</td>\n",
       "      <td>0.077701</td>\n",
       "      <td>0.033148</td>\n",
       "      <td>0.154497</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.096368</td>\n",
       "      <td>-0.089640</td>\n",
       "      <td>0.087655</td>\n",
       "      <td>0.008480</td>\n",
       "      <td>0.014096</td>\n",
       "      <td>0.016017</td>\n",
       "      <td>-0.014791</td>\n",
       "      <td>0.047992</td>\n",
       "      <td>-0.061708</td>\n",
       "      <td>-0.072145</td>\n",
       "      <td>-0.123401</td>\n",
       "      <td>0.028897</td>\n",
       "      <td>0.055361</td>\n",
       "      <td>-0.095297</td>\n",
       "      <td>-0.130906</td>\n",
       "      <td>-0.056640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsa</th>\n",
       "      <td>0.177885</td>\n",
       "      <td>0.224309</td>\n",
       "      <td>-0.117260</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>-0.014147</td>\n",
       "      <td>0.016545</td>\n",
       "      <td>-0.097230</td>\n",
       "      <td>-0.096368</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.055216</td>\n",
       "      <td>-0.231449</td>\n",
       "      <td>0.098553</td>\n",
       "      <td>-0.006885</td>\n",
       "      <td>-0.098107</td>\n",
       "      <td>0.007973</td>\n",
       "      <td>0.017948</td>\n",
       "      <td>0.010028</td>\n",
       "      <td>0.046049</td>\n",
       "      <td>0.145965</td>\n",
       "      <td>0.107216</td>\n",
       "      <td>-0.030039</td>\n",
       "      <td>0.200124</td>\n",
       "      <td>-0.110918</td>\n",
       "      <td>0.004473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>northcen</th>\n",
       "      <td>-0.029124</td>\n",
       "      <td>0.061372</td>\n",
       "      <td>0.010588</td>\n",
       "      <td>0.014093</td>\n",
       "      <td>-0.080201</td>\n",
       "      <td>0.015453</td>\n",
       "      <td>-0.011716</td>\n",
       "      <td>-0.089640</td>\n",
       "      <td>0.055216</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.429892</td>\n",
       "      <td>-0.261212</td>\n",
       "      <td>-0.021493</td>\n",
       "      <td>-0.000787</td>\n",
       "      <td>-0.059439</td>\n",
       "      <td>0.020417</td>\n",
       "      <td>-0.062645</td>\n",
       "      <td>0.068810</td>\n",
       "      <td>0.068841</td>\n",
       "      <td>-0.024479</td>\n",
       "      <td>0.043253</td>\n",
       "      <td>-0.015858</td>\n",
       "      <td>0.033540</td>\n",
       "      <td>0.009093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>south</th>\n",
       "      <td>-0.102503</td>\n",
       "      <td>-0.116625</td>\n",
       "      <td>0.050323</td>\n",
       "      <td>-0.025067</td>\n",
       "      <td>0.102098</td>\n",
       "      <td>-0.044438</td>\n",
       "      <td>0.075150</td>\n",
       "      <td>0.087655</td>\n",
       "      <td>-0.231449</td>\n",
       "      <td>-0.429892</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.335178</td>\n",
       "      <td>0.027934</td>\n",
       "      <td>0.120806</td>\n",
       "      <td>0.015989</td>\n",
       "      <td>0.029125</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>-0.084814</td>\n",
       "      <td>-0.103949</td>\n",
       "      <td>0.028889</td>\n",
       "      <td>-0.026364</td>\n",
       "      <td>-0.090454</td>\n",
       "      <td>0.021216</td>\n",
       "      <td>-0.029205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>west</th>\n",
       "      <td>0.087732</td>\n",
       "      <td>0.016343</td>\n",
       "      <td>-0.017398</td>\n",
       "      <td>-0.021291</td>\n",
       "      <td>-0.002287</td>\n",
       "      <td>0.054417</td>\n",
       "      <td>-0.022277</td>\n",
       "      <td>0.008480</td>\n",
       "      <td>0.098553</td>\n",
       "      <td>-0.261212</td>\n",
       "      <td>-0.335178</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001478</td>\n",
       "      <td>-0.098131</td>\n",
       "      <td>0.052281</td>\n",
       "      <td>-0.039784</td>\n",
       "      <td>0.067926</td>\n",
       "      <td>-0.034875</td>\n",
       "      <td>-0.006901</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>-0.022180</td>\n",
       "      <td>0.072298</td>\n",
       "      <td>-0.023133</td>\n",
       "      <td>-0.040805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>construc</th>\n",
       "      <td>0.004034</td>\n",
       "      <td>-0.077411</td>\n",
       "      <td>-0.072841</td>\n",
       "      <td>-0.025888</td>\n",
       "      <td>0.046109</td>\n",
       "      <td>-0.082032</td>\n",
       "      <td>0.007452</td>\n",
       "      <td>0.014096</td>\n",
       "      <td>-0.006885</td>\n",
       "      <td>-0.021493</td>\n",
       "      <td>0.027934</td>\n",
       "      <td>-0.001478</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.078458</td>\n",
       "      <td>-0.046756</td>\n",
       "      <td>-0.138748</td>\n",
       "      <td>-0.073192</td>\n",
       "      <td>-0.129119</td>\n",
       "      <td>-0.090849</td>\n",
       "      <td>0.024038</td>\n",
       "      <td>-0.088471</td>\n",
       "      <td>0.022563</td>\n",
       "      <td>-0.066560</td>\n",
       "      <td>-0.028789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ndurman</th>\n",
       "      <td>0.073725</td>\n",
       "      <td>-0.012461</td>\n",
       "      <td>0.101432</td>\n",
       "      <td>0.160519</td>\n",
       "      <td>0.036261</td>\n",
       "      <td>-0.092721</td>\n",
       "      <td>0.079615</td>\n",
       "      <td>0.016017</td>\n",
       "      <td>-0.098107</td>\n",
       "      <td>-0.000787</td>\n",
       "      <td>0.120806</td>\n",
       "      <td>-0.098131</td>\n",
       "      <td>-0.078458</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.076730</td>\n",
       "      <td>-0.227696</td>\n",
       "      <td>-0.120113</td>\n",
       "      <td>-0.211895</td>\n",
       "      <td>-0.000189</td>\n",
       "      <td>-0.128792</td>\n",
       "      <td>-0.110787</td>\n",
       "      <td>0.082614</td>\n",
       "      <td>0.093953</td>\n",
       "      <td>0.126454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trcommpu</th>\n",
       "      <td>0.055940</td>\n",
       "      <td>0.107736</td>\n",
       "      <td>-0.048267</td>\n",
       "      <td>0.063885</td>\n",
       "      <td>-0.072328</td>\n",
       "      <td>-0.018964</td>\n",
       "      <td>0.038239</td>\n",
       "      <td>-0.014791</td>\n",
       "      <td>0.007973</td>\n",
       "      <td>-0.059439</td>\n",
       "      <td>0.015989</td>\n",
       "      <td>0.052281</td>\n",
       "      <td>-0.046756</td>\n",
       "      <td>-0.076730</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.135692</td>\n",
       "      <td>-0.071579</td>\n",
       "      <td>-0.126275</td>\n",
       "      <td>-0.008472</td>\n",
       "      <td>0.078516</td>\n",
       "      <td>-0.059783</td>\n",
       "      <td>0.077205</td>\n",
       "      <td>-0.043717</td>\n",
       "      <td>0.051774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trade</th>\n",
       "      <td>-0.189848</td>\n",
       "      <td>-0.059204</td>\n",
       "      <td>-0.104626</td>\n",
       "      <td>-0.126224</td>\n",
       "      <td>-0.048486</td>\n",
       "      <td>-0.053351</td>\n",
       "      <td>-0.136572</td>\n",
       "      <td>0.047992</td>\n",
       "      <td>0.017948</td>\n",
       "      <td>0.020417</td>\n",
       "      <td>0.029125</td>\n",
       "      <td>-0.039784</td>\n",
       "      <td>-0.138748</td>\n",
       "      <td>-0.227696</td>\n",
       "      <td>-0.135692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.212413</td>\n",
       "      <td>-0.374723</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.036731</td>\n",
       "      <td>0.033318</td>\n",
       "      <td>-0.214694</td>\n",
       "      <td>-0.083102</td>\n",
       "      <td>-0.092353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>services</th>\n",
       "      <td>-0.141624</td>\n",
       "      <td>-0.072659</td>\n",
       "      <td>0.041499</td>\n",
       "      <td>-0.062604</td>\n",
       "      <td>0.094866</td>\n",
       "      <td>0.108833</td>\n",
       "      <td>-0.054906</td>\n",
       "      <td>-0.061708</td>\n",
       "      <td>0.010028</td>\n",
       "      <td>-0.062645</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.067926</td>\n",
       "      <td>-0.073192</td>\n",
       "      <td>-0.120113</td>\n",
       "      <td>-0.071579</td>\n",
       "      <td>-0.212413</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.197672</td>\n",
       "      <td>-0.123794</td>\n",
       "      <td>-0.031591</td>\n",
       "      <td>0.173360</td>\n",
       "      <td>-0.187391</td>\n",
       "      <td>0.050088</td>\n",
       "      <td>-0.025516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>profserv</th>\n",
       "      <td>0.085204</td>\n",
       "      <td>0.214198</td>\n",
       "      <td>-0.020599</td>\n",
       "      <td>-0.059691</td>\n",
       "      <td>-0.056680</td>\n",
       "      <td>0.215939</td>\n",
       "      <td>0.064603</td>\n",
       "      <td>-0.072145</td>\n",
       "      <td>0.046049</td>\n",
       "      <td>0.068810</td>\n",
       "      <td>-0.084814</td>\n",
       "      <td>-0.034875</td>\n",
       "      <td>-0.129119</td>\n",
       "      <td>-0.211895</td>\n",
       "      <td>-0.126275</td>\n",
       "      <td>-0.374723</td>\n",
       "      <td>-0.197672</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.163055</td>\n",
       "      <td>0.189009</td>\n",
       "      <td>0.098243</td>\n",
       "      <td>0.112766</td>\n",
       "      <td>-0.028370</td>\n",
       "      <td>-0.081666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>profocc</th>\n",
       "      <td>0.441770</td>\n",
       "      <td>0.496768</td>\n",
       "      <td>-0.005615</td>\n",
       "      <td>0.090624</td>\n",
       "      <td>-0.088552</td>\n",
       "      <td>-0.177376</td>\n",
       "      <td>0.085544</td>\n",
       "      <td>-0.123401</td>\n",
       "      <td>0.145965</td>\n",
       "      <td>0.068841</td>\n",
       "      <td>-0.103949</td>\n",
       "      <td>-0.006901</td>\n",
       "      <td>-0.090849</td>\n",
       "      <td>-0.000189</td>\n",
       "      <td>-0.008472</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.123794</td>\n",
       "      <td>0.163055</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.341241</td>\n",
       "      <td>-0.308037</td>\n",
       "      <td>0.445143</td>\n",
       "      <td>-0.037135</td>\n",
       "      <td>0.043595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clerocc</th>\n",
       "      <td>-0.140837</td>\n",
       "      <td>-0.008324</td>\n",
       "      <td>-0.040385</td>\n",
       "      <td>-0.072831</td>\n",
       "      <td>-0.034138</td>\n",
       "      <td>0.355233</td>\n",
       "      <td>0.025711</td>\n",
       "      <td>0.028897</td>\n",
       "      <td>0.107216</td>\n",
       "      <td>-0.024479</td>\n",
       "      <td>0.028889</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>0.024038</td>\n",
       "      <td>-0.128792</td>\n",
       "      <td>0.078516</td>\n",
       "      <td>-0.036731</td>\n",
       "      <td>-0.031591</td>\n",
       "      <td>0.189009</td>\n",
       "      <td>-0.341241</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.181364</td>\n",
       "      <td>-0.119043</td>\n",
       "      <td>-0.045637</td>\n",
       "      <td>-0.047785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>servocc</th>\n",
       "      <td>-0.253078</td>\n",
       "      <td>-0.163345</td>\n",
       "      <td>-0.071080</td>\n",
       "      <td>-0.112679</td>\n",
       "      <td>-0.028769</td>\n",
       "      <td>0.159226</td>\n",
       "      <td>-0.157040</td>\n",
       "      <td>0.055361</td>\n",
       "      <td>-0.030039</td>\n",
       "      <td>0.043253</td>\n",
       "      <td>-0.026364</td>\n",
       "      <td>-0.022180</td>\n",
       "      <td>-0.088471</td>\n",
       "      <td>-0.110787</td>\n",
       "      <td>-0.059783</td>\n",
       "      <td>0.033318</td>\n",
       "      <td>0.173360</td>\n",
       "      <td>0.098243</td>\n",
       "      <td>-0.308037</td>\n",
       "      <td>-0.181364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.318303</td>\n",
       "      <td>-0.020604</td>\n",
       "      <td>-0.075965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lwage</th>\n",
       "      <td>0.937062</td>\n",
       "      <td>0.431053</td>\n",
       "      <td>0.111373</td>\n",
       "      <td>0.325538</td>\n",
       "      <td>-0.038888</td>\n",
       "      <td>-0.373677</td>\n",
       "      <td>0.270669</td>\n",
       "      <td>-0.095297</td>\n",
       "      <td>0.200124</td>\n",
       "      <td>-0.015858</td>\n",
       "      <td>-0.090454</td>\n",
       "      <td>0.072298</td>\n",
       "      <td>0.022563</td>\n",
       "      <td>0.082614</td>\n",
       "      <td>0.077205</td>\n",
       "      <td>-0.214694</td>\n",
       "      <td>-0.187391</td>\n",
       "      <td>0.112766</td>\n",
       "      <td>0.445143</td>\n",
       "      <td>-0.119043</td>\n",
       "      <td>-0.318303</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023298</td>\n",
       "      <td>0.236083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expersq</th>\n",
       "      <td>0.030238</td>\n",
       "      <td>-0.331256</td>\n",
       "      <td>0.960971</td>\n",
       "      <td>0.459223</td>\n",
       "      <td>0.009348</td>\n",
       "      <td>-0.027860</td>\n",
       "      <td>0.217289</td>\n",
       "      <td>-0.130906</td>\n",
       "      <td>-0.110918</td>\n",
       "      <td>0.033540</td>\n",
       "      <td>0.021216</td>\n",
       "      <td>-0.023133</td>\n",
       "      <td>-0.066560</td>\n",
       "      <td>0.093953</td>\n",
       "      <td>-0.043717</td>\n",
       "      <td>-0.083102</td>\n",
       "      <td>0.050088</td>\n",
       "      <td>-0.028370</td>\n",
       "      <td>-0.037135</td>\n",
       "      <td>-0.045637</td>\n",
       "      <td>-0.020604</td>\n",
       "      <td>0.023298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.413950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tenursq</th>\n",
       "      <td>0.267419</td>\n",
       "      <td>-0.069106</td>\n",
       "      <td>0.422942</td>\n",
       "      <td>0.921564</td>\n",
       "      <td>-0.007203</td>\n",
       "      <td>-0.175623</td>\n",
       "      <td>0.166822</td>\n",
       "      <td>-0.056640</td>\n",
       "      <td>0.004473</td>\n",
       "      <td>0.009093</td>\n",
       "      <td>-0.029205</td>\n",
       "      <td>-0.040805</td>\n",
       "      <td>-0.028789</td>\n",
       "      <td>0.126454</td>\n",
       "      <td>0.051774</td>\n",
       "      <td>-0.092353</td>\n",
       "      <td>-0.025516</td>\n",
       "      <td>-0.081666</td>\n",
       "      <td>0.043595</td>\n",
       "      <td>-0.047785</td>\n",
       "      <td>-0.075965</td>\n",
       "      <td>0.236083</td>\n",
       "      <td>0.413950</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              wage      educ     exper  ...     lwage   expersq   tenursq\n",
       "wage      1.000000  0.405903  0.112903  ...  0.937062  0.030238  0.267419\n",
       "educ      0.405903  1.000000 -0.299542  ...  0.431053 -0.331256 -0.069106\n",
       "exper     0.112903 -0.299542  1.000000  ...  0.111373  0.960971  0.422942\n",
       "tenure    0.346890 -0.056173  0.499291  ...  0.325538  0.459223  0.921564\n",
       "nonwhite -0.038520 -0.084654  0.014356  ... -0.038888  0.009348 -0.007203\n",
       "female   -0.340098 -0.085029 -0.041626  ... -0.373677 -0.027860 -0.175623\n",
       "married   0.228817  0.068881  0.316984  ...  0.270669  0.217289  0.166822\n",
       "numdep   -0.053760 -0.215291 -0.056319  ... -0.095297 -0.130906 -0.056640\n",
       "smsa      0.177885  0.224309 -0.117260  ...  0.200124 -0.110918  0.004473\n",
       "northcen -0.029124  0.061372  0.010588  ... -0.015858  0.033540  0.009093\n",
       "south    -0.102503 -0.116625  0.050323  ... -0.090454  0.021216 -0.029205\n",
       "west      0.087732  0.016343 -0.017398  ...  0.072298 -0.023133 -0.040805\n",
       "construc  0.004034 -0.077411 -0.072841  ...  0.022563 -0.066560 -0.028789\n",
       "ndurman   0.073725 -0.012461  0.101432  ...  0.082614  0.093953  0.126454\n",
       "trcommpu  0.055940  0.107736 -0.048267  ...  0.077205 -0.043717  0.051774\n",
       "trade    -0.189848 -0.059204 -0.104626  ... -0.214694 -0.083102 -0.092353\n",
       "services -0.141624 -0.072659  0.041499  ... -0.187391  0.050088 -0.025516\n",
       "profserv  0.085204  0.214198 -0.020599  ...  0.112766 -0.028370 -0.081666\n",
       "profocc   0.441770  0.496768 -0.005615  ...  0.445143 -0.037135  0.043595\n",
       "clerocc  -0.140837 -0.008324 -0.040385  ... -0.119043 -0.045637 -0.047785\n",
       "servocc  -0.253078 -0.163345 -0.071080  ... -0.318303 -0.020604 -0.075965\n",
       "lwage     0.937062  0.431053  0.111373  ...  1.000000  0.023298  0.236083\n",
       "expersq   0.030238 -0.331256  0.960971  ...  0.023298  1.000000  0.413950\n",
       "tenursq   0.267419 -0.069106  0.422942  ...  0.236083  0.413950  1.000000\n",
       "\n",
       "[24 rows x 24 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#coeficiente de correlaciones entre variables\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg=smf.ols(formula=\"lwage~educ+exper+expersq+tenure+female\",data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>lwage</td>      <th>  R-squared:         </th> <td>   0.434</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.429</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   79.77</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 27 Jan 2022</td> <th>  Prob (F-statistic):</th> <td>4.78e-62</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:04:52</td>     <th>  Log-Likelihood:    </th> <td> -263.72</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   526</td>      <th>  AIC:               </th> <td>   539.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   520</td>      <th>  BIC:               </th> <td>   565.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.4146</td> <td>    0.099</td> <td>    4.171</td> <td> 0.000</td> <td>    0.219</td> <td>    0.610</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educ</th>      <td>    0.0810</td> <td>    0.007</td> <td>   11.934</td> <td> 0.000</td> <td>    0.068</td> <td>    0.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exper</th>     <td>    0.0328</td> <td>    0.005</td> <td>    6.820</td> <td> 0.000</td> <td>    0.023</td> <td>    0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>expersq</th>   <td>   -0.0006</td> <td>    0.000</td> <td>   -6.197</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>    <td>    0.0162</td> <td>    0.003</td> <td>    5.629</td> <td> 0.000</td> <td>    0.011</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>female</th>    <td>   -0.2979</td> <td>    0.036</td> <td>   -8.280</td> <td> 0.000</td> <td>   -0.369</td> <td>   -0.227</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.455</td> <th>  Durbin-Watson:     </th> <td>   1.775</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  27.752</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.097</td> <th>  Prob(JB):          </th> <td>9.41e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.108</td> <th>  Cond. No.          </th> <td>4.44e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 4.44e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  lwage   R-squared:                       0.434\n",
       "Model:                            OLS   Adj. R-squared:                  0.429\n",
       "Method:                 Least Squares   F-statistic:                     79.77\n",
       "Date:                Thu, 27 Jan 2022   Prob (F-statistic):           4.78e-62\n",
       "Time:                        17:04:52   Log-Likelihood:                -263.72\n",
       "No. Observations:                 526   AIC:                             539.4\n",
       "Df Residuals:                     520   BIC:                             565.0\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.4146      0.099      4.171      0.000       0.219       0.610\n",
       "educ           0.0810      0.007     11.934      0.000       0.068       0.094\n",
       "exper          0.0328      0.005      6.820      0.000       0.023       0.042\n",
       "expersq       -0.0006      0.000     -6.197      0.000      -0.001      -0.000\n",
       "tenure         0.0162      0.003      5.629      0.000       0.011       0.022\n",
       "female        -0.2979      0.036     -8.280      0.000      -0.369      -0.227\n",
       "==============================================================================\n",
       "Omnibus:                       14.455   Durbin-Watson:                   1.775\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               27.752\n",
       "Skew:                          -0.097   Prob(JB):                     9.41e-07\n",
       "Kurtosis:                       4.108   Cond. No.                     4.44e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 4.44e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado=reg.fit()\n",
    "resultado.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos una interaccion. multiplicamos el valor de female por el de married.\n",
    "\n",
    "reg=smf.ols(formula=\"lwage~educ+exper+expersq+tenure+female*married\",data=df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>lwage</td>      <th>  R-squared:         </th> <td>   0.455</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.448</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   61.86</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 27 Jan 2022</td> <th>  Prob (F-statistic):</th> <td>2.13e-64</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:09:26</td>     <th>  Log-Likelihood:    </th> <td> -253.65</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   526</td>      <th>  AIC:               </th> <td>   523.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   518</td>      <th>  BIC:               </th> <td>   557.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>      <td>    0.3173</td> <td>    0.100</td> <td>    3.160</td> <td> 0.002</td> <td>    0.120</td> <td>    0.515</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educ</th>           <td>    0.0795</td> <td>    0.007</td> <td>   11.841</td> <td> 0.000</td> <td>    0.066</td> <td>    0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exper</th>          <td>    0.0297</td> <td>    0.005</td> <td>    5.815</td> <td> 0.000</td> <td>    0.020</td> <td>    0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>expersq</th>        <td>   -0.0006</td> <td>    0.000</td> <td>   -5.475</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>         <td>    0.0149</td> <td>    0.003</td> <td>    5.247</td> <td> 0.000</td> <td>    0.009</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>female</th>         <td>   -0.1070</td> <td>    0.056</td> <td>   -1.912</td> <td> 0.056</td> <td>   -0.217</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>married</th>        <td>    0.2197</td> <td>    0.056</td> <td>    3.958</td> <td> 0.000</td> <td>    0.111</td> <td>    0.329</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>female:married</th> <td>   -0.3076</td> <td>    0.072</td> <td>   -4.273</td> <td> 0.000</td> <td>   -0.449</td> <td>   -0.166</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>16.140</td> <th>  Durbin-Watson:     </th> <td>   1.767</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  33.927</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.072</td> <th>  Prob(JB):          </th> <td>4.29e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.236</td> <th>  Cond. No.          </th> <td>5.00e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large,  5e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  lwage   R-squared:                       0.455\n",
       "Model:                            OLS   Adj. R-squared:                  0.448\n",
       "Method:                 Least Squares   F-statistic:                     61.86\n",
       "Date:                Thu, 27 Jan 2022   Prob (F-statistic):           2.13e-64\n",
       "Time:                        17:09:26   Log-Likelihood:                -253.65\n",
       "No. Observations:                 526   AIC:                             523.3\n",
       "Df Residuals:                     518   BIC:                             557.4\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==================================================================================\n",
       "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "Intercept          0.3173      0.100      3.160      0.002       0.120       0.515\n",
       "educ               0.0795      0.007     11.841      0.000       0.066       0.093\n",
       "exper              0.0297      0.005      5.815      0.000       0.020       0.040\n",
       "expersq           -0.0006      0.000     -5.475      0.000      -0.001      -0.000\n",
       "tenure             0.0149      0.003      5.247      0.000       0.009       0.021\n",
       "female            -0.1070      0.056     -1.912      0.056      -0.217       0.003\n",
       "married            0.2197      0.056      3.958      0.000       0.111       0.329\n",
       "female:married    -0.3076      0.072     -4.273      0.000      -0.449      -0.166\n",
       "==============================================================================\n",
       "Omnibus:                       16.140   Durbin-Watson:                   1.767\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               33.927\n",
       "Skew:                          -0.072   Prob(JB):                     4.29e-08\n",
       "Kurtosis:                       4.236   Cond. No.                     5.00e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large,  5e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado=reg.fit()\n",
    "resultado.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vamos a trabajar con 4 supuestos\n",
    "# 1: No multicolinealidad\n",
    "# 2: Homocedasticidad. si este supuesto no se cumple (p valor menor de 0.05) los estimadores son ineficientes.\n",
    "# no podemos hacer predicciones, solo interpretar\n",
    "# 3: Autocorrelación\n",
    "# 4: Distribución normal de los errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#supuesto número 1: multicolinealidad. si tengo varias variables, no puede depender linealmente una variable de otra\n",
    "#ej: x1 no puede ser 3 veces x2, o 3+5x3 por ejemplo.\n",
    "#hemos detectar si tenemos multicolinealidd en las variables numericas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#supuesto 2 Homocedasticidad. la varianza de los errores da unas variables constantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "hprice1=wo.dataWoo(\"hprice1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg=smf.ols(formula=\"price~lotsize+sqrft+bdrms\",data=hprice1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th> <td>   0.672</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.661</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   24.85</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 27 Jan 2022</td> <th>  Prob (F-statistic):</th> <td>1.33e-11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:35:52</td>     <th>  Log-Likelihood:    </th> <td> -482.88</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    88</td>      <th>  AIC:               </th> <td>   973.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    84</td>      <th>  BIC:               </th> <td>   983.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>         <td>HC0</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  -21.7703</td> <td>   36.284</td> <td>   -0.600</td> <td> 0.549</td> <td>  -92.886</td> <td>   49.346</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lotsize</th>   <td>    0.0021</td> <td>    0.001</td> <td>    1.691</td> <td> 0.091</td> <td>   -0.000</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqrft</th>     <td>    0.1228</td> <td>    0.017</td> <td>    7.090</td> <td> 0.000</td> <td>    0.089</td> <td>    0.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bdrms</th>     <td>   13.8525</td> <td>    8.284</td> <td>    1.672</td> <td> 0.094</td> <td>   -2.383</td> <td>   30.088</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>20.398</td> <th>  Durbin-Watson:     </th> <td>   2.110</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  32.278</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.961</td> <th>  Prob(JB):          </th> <td>9.79e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.261</td> <th>  Cond. No.          </th> <td>6.41e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC0)<br/>[2] The condition number is large, 6.41e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.672\n",
       "Model:                            OLS   Adj. R-squared:                  0.661\n",
       "Method:                 Least Squares   F-statistic:                     24.85\n",
       "Date:                Thu, 27 Jan 2022   Prob (F-statistic):           1.33e-11\n",
       "Time:                        17:35:52   Log-Likelihood:                -482.88\n",
       "No. Observations:                  88   AIC:                             973.8\n",
       "Df Residuals:                      84   BIC:                             983.7\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:                  HC0                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    -21.7703     36.284     -0.600      0.549     -92.886      49.346\n",
       "lotsize        0.0021      0.001      1.691      0.091      -0.000       0.004\n",
       "sqrft          0.1228      0.017      7.090      0.000       0.089       0.157\n",
       "bdrms         13.8525      8.284      1.672      0.094      -2.383      30.088\n",
       "==============================================================================\n",
       "Omnibus:                       20.398   Durbin-Watson:                   2.110\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               32.278\n",
       "Skew:                           0.961   Prob(JB):                     9.79e-08\n",
       "Kurtosis:                       5.261   Cond. No.                     6.41e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC0)\n",
       "[2] The condition number is large, 6.41e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado=reg.fit(cov_type=\"HC0\")  \n",
    "resultado.summary()\n",
    "\n",
    "#dentro del fit ponemos el tipo de covarianza HC0 para corregir la no homocedasticidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test de Breusch-Pagan pra hacer el test de homocedasticidad\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: patsy in c:\\users\\alfredo\\anaconda3\\lib\\site-packages (0.5.2)\n",
      "Requirement already satisfied: numpy>=1.4 in c:\\users\\alfredo\\anaconda3\\lib\\site-packages (from patsy) (1.19.5)\n",
      "Requirement already satisfied: six in c:\\users\\alfredo\\appdata\\roaming\\python\\python38\\site-packages (from patsy) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install patsy\n",
    "import patsy as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y,X=pt.dmatrices(\"price~lotsize+sqrft+bdrms\",data=hprice1,return_type=\"dataframe\")\n",
    "bp_lm=sm.stats.diagnostic.het_breuschpagan(resultado.resid,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0027820595556890867"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp_lm[1] \n",
    "#el valor 0 es la estadistico y el 1 es el p valor\n",
    "#si tenemos un p valor (menor de 0.05) diremos que nuestro modelo es heterocedastico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2383448263149274\n"
     ]
    }
   ],
   "source": [
    "#una manera de corregirlo es cambiando la forma funcional, ponemos las variables de forma logaritmica. precio, tamaño,etc...\n",
    "# son variables continuas, las usamos. bedrroms no lo cambiamos porque es una variable discreta,de numeros enteros.\n",
    "\n",
    "reg=smf.ols(formula=\"np.log(price)~np.log(lotsize)+np.log(sqrft)+bdrms\",data=hprice1)\n",
    "resultado=reg.fit()\n",
    "#test\n",
    "y,X=pt.dmatrices(\"np.log(price)~np.log(lotsize)+np.log(sqrft)+bdrms\",data=hprice1,return_type=\"dataframe\")\n",
    "bp_lm=sm.stats.diagnostic.het_breuschpagan(resultado.resid,X)\n",
    "print(bp_lm[1])\n",
    "\n",
    "#nuestro modelo esta por encima de 0.05, ya no es heterocedastico es homocedastico.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>assess</th>\n",
       "      <th>bdrms</th>\n",
       "      <th>lotsize</th>\n",
       "      <th>sqrft</th>\n",
       "      <th>colonial</th>\n",
       "      <th>lprice</th>\n",
       "      <th>lassess</th>\n",
       "      <th>llotsize</th>\n",
       "      <th>lsqrft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300.0</td>\n",
       "      <td>349.100006</td>\n",
       "      <td>4</td>\n",
       "      <td>6126.0</td>\n",
       "      <td>2438</td>\n",
       "      <td>1</td>\n",
       "      <td>5.703783</td>\n",
       "      <td>5.855359</td>\n",
       "      <td>8.720297</td>\n",
       "      <td>7.798934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>370.0</td>\n",
       "      <td>351.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>9903.0</td>\n",
       "      <td>2076</td>\n",
       "      <td>1</td>\n",
       "      <td>5.913503</td>\n",
       "      <td>5.862210</td>\n",
       "      <td>9.200593</td>\n",
       "      <td>7.638198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>191.0</td>\n",
       "      <td>217.699997</td>\n",
       "      <td>3</td>\n",
       "      <td>5200.0</td>\n",
       "      <td>1374</td>\n",
       "      <td>0</td>\n",
       "      <td>5.252274</td>\n",
       "      <td>5.383118</td>\n",
       "      <td>8.556414</td>\n",
       "      <td>7.225482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195.0</td>\n",
       "      <td>231.800003</td>\n",
       "      <td>3</td>\n",
       "      <td>4600.0</td>\n",
       "      <td>1448</td>\n",
       "      <td>1</td>\n",
       "      <td>5.273000</td>\n",
       "      <td>5.445875</td>\n",
       "      <td>8.433811</td>\n",
       "      <td>7.277938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>373.0</td>\n",
       "      <td>319.100006</td>\n",
       "      <td>4</td>\n",
       "      <td>6095.0</td>\n",
       "      <td>2514</td>\n",
       "      <td>1</td>\n",
       "      <td>5.921578</td>\n",
       "      <td>5.765504</td>\n",
       "      <td>8.715224</td>\n",
       "      <td>7.829630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>295.0</td>\n",
       "      <td>318.299988</td>\n",
       "      <td>3</td>\n",
       "      <td>6056.0</td>\n",
       "      <td>1837</td>\n",
       "      <td>1</td>\n",
       "      <td>5.686975</td>\n",
       "      <td>5.762994</td>\n",
       "      <td>8.708805</td>\n",
       "      <td>7.515889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>236.0</td>\n",
       "      <td>259.399994</td>\n",
       "      <td>3</td>\n",
       "      <td>5828.0</td>\n",
       "      <td>1715</td>\n",
       "      <td>0</td>\n",
       "      <td>5.463832</td>\n",
       "      <td>5.558371</td>\n",
       "      <td>8.670429</td>\n",
       "      <td>7.447168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>202.5</td>\n",
       "      <td>258.100006</td>\n",
       "      <td>3</td>\n",
       "      <td>6341.0</td>\n",
       "      <td>1574</td>\n",
       "      <td>0</td>\n",
       "      <td>5.310740</td>\n",
       "      <td>5.553347</td>\n",
       "      <td>8.754792</td>\n",
       "      <td>7.361375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>219.0</td>\n",
       "      <td>232.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>6362.0</td>\n",
       "      <td>1185</td>\n",
       "      <td>0</td>\n",
       "      <td>5.389072</td>\n",
       "      <td>5.446737</td>\n",
       "      <td>8.758098</td>\n",
       "      <td>7.077498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>242.0</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4950.0</td>\n",
       "      <td>1774</td>\n",
       "      <td>1</td>\n",
       "      <td>5.488938</td>\n",
       "      <td>5.529429</td>\n",
       "      <td>8.507143</td>\n",
       "      <td>7.480992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    price      assess  bdrms  lotsize  ...    lprice   lassess  llotsize    lsqrft\n",
       "0   300.0  349.100006      4   6126.0  ...  5.703783  5.855359  8.720297  7.798934\n",
       "1   370.0  351.500000      3   9903.0  ...  5.913503  5.862210  9.200593  7.638198\n",
       "2   191.0  217.699997      3   5200.0  ...  5.252274  5.383118  8.556414  7.225482\n",
       "3   195.0  231.800003      3   4600.0  ...  5.273000  5.445875  8.433811  7.277938\n",
       "4   373.0  319.100006      4   6095.0  ...  5.921578  5.765504  8.715224  7.829630\n",
       "..    ...         ...    ...      ...  ...       ...       ...       ...       ...\n",
       "83  295.0  318.299988      3   6056.0  ...  5.686975  5.762994  8.708805  7.515889\n",
       "84  236.0  259.399994      3   5828.0  ...  5.463832  5.558371  8.670429  7.447168\n",
       "85  202.5  258.100006      3   6341.0  ...  5.310740  5.553347  8.754792  7.361375\n",
       "86  219.0  232.000000      2   6362.0  ...  5.389072  5.446737  8.758098  7.077498\n",
       "87  242.0  252.000000      4   4950.0  ...  5.488938  5.529429  8.507143  7.480992\n",
       "\n",
       "[88 rows x 10 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hprice1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>np.log(price)</td>  <th>  R-squared:         </th> <td>   0.643</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.630</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   50.42</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 27 Jan 2022</td> <th>  Prob (F-statistic):</th> <td>9.74e-19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:58:19</td>     <th>  Log-Likelihood:    </th> <td>  25.861</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    88</td>      <th>  AIC:               </th> <td>  -43.72</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    84</td>      <th>  BIC:               </th> <td>  -33.81</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>       <td>   -1.2970</td> <td>    0.651</td> <td>   -1.992</td> <td> 0.050</td> <td>   -2.592</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>np.log(lotsize)</th> <td>    0.1680</td> <td>    0.038</td> <td>    4.388</td> <td> 0.000</td> <td>    0.092</td> <td>    0.244</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>np.log(sqrft)</th>   <td>    0.7002</td> <td>    0.093</td> <td>    7.540</td> <td> 0.000</td> <td>    0.516</td> <td>    0.885</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bdrms</th>           <td>    0.0370</td> <td>    0.028</td> <td>    1.342</td> <td> 0.183</td> <td>   -0.018</td> <td>    0.092</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>12.060</td> <th>  Durbin-Watson:     </th> <td>   2.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.002</td> <th>  Jarque-Bera (JB):  </th> <td>  34.889</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.188</td> <th>  Prob(JB):          </th> <td>2.65e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.062</td> <th>  Cond. No.          </th> <td>    410.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:          np.log(price)   R-squared:                       0.643\n",
       "Model:                            OLS   Adj. R-squared:                  0.630\n",
       "Method:                 Least Squares   F-statistic:                     50.42\n",
       "Date:                Thu, 27 Jan 2022   Prob (F-statistic):           9.74e-19\n",
       "Time:                        17:58:19   Log-Likelihood:                 25.861\n",
       "No. Observations:                  88   AIC:                            -43.72\n",
       "Df Residuals:                      84   BIC:                            -33.81\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================\n",
       "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "Intercept          -1.2970      0.651     -1.992      0.050      -2.592      -0.002\n",
       "np.log(lotsize)     0.1680      0.038      4.388      0.000       0.092       0.244\n",
       "np.log(sqrft)       0.7002      0.093      7.540      0.000       0.516       0.885\n",
       "bdrms               0.0370      0.028      1.342      0.183      -0.018       0.092\n",
       "==============================================================================\n",
       "Omnibus:                       12.060   Durbin-Watson:                   2.089\n",
       "Prob(Omnibus):                  0.002   Jarque-Bera (JB):               34.889\n",
       "Skew:                          -0.188   Prob(JB):                     2.65e-08\n",
       "Kurtosis:                       6.062   Cond. No.                         410.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ec4841e23e60b894d6eebb345ecb3aed015c86bfa40b953e91bb574c27cc9f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
